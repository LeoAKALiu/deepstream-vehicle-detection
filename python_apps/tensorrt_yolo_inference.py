#!/usr/bin/env python3
"""
æ··åˆæ–¹æ¡ˆï¼šTensorRT GPUæ¨ç† + Pythonåå¤„ç†
- GPU: TensorRTæ¨ç†ï¼ˆä½¿ç”¨pycudaï¼‰
- CPU: YOLOè¾“å‡ºè§£æã€ByteTrackè·Ÿè¸ªã€HyperLPRè½¦ç‰Œè¯†åˆ«
"""

import sys
import time
import cv2
import numpy as np
from pathlib import Path
from collections import defaultdict

# TensorRTå’ŒCUDA
try:
    import pycuda.driver as cuda
    import pycuda.autoinit
    import tensorrt as trt
    TRT_AVAILABLE = True
    print("âœ“ TensorRTå’ŒPyCUDAå¯ç”¨")
except ImportError as e:
    TRT_AVAILABLE = False
    print(f"âœ— TensorRT/PyCUDAä¸å¯ç”¨: {e}")
    print("  è¯·åœ¨å®¹å™¨ä¸­è¿è¡Œæˆ–ä½¿ç”¨CPUæ–¹æ¡ˆ")
    sys.exit(1)

# ByteTrackè·Ÿè¸ª
try:
    from byte_tracker import BYTETracker
    BYTETRACK_AVAILABLE = True
    print("âœ“ ByteTrackå¯ç”¨")
except ImportError:
    BYTETRACK_AVAILABLE = False
    print("âš  ByteTrackä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç®€å•è·Ÿè¸ª")

# HyperLPRè½¦ç‰Œè¯†åˆ«
try:
    from hyperlpr3 import LicensePlateCN
    HYPERLPR_AVAILABLE = True
    print("âœ“ HyperLPRå¯ç”¨")
except ImportError:
    HYPERLPR_AVAILABLE = False
    print("âš  HyperLPRä¸å¯ç”¨ï¼Œè·³è¿‡è½¦ç‰Œè¯†åˆ«")


# è½¦è¾†ç±»åˆ«
CONSTRUCTION_VEHICLES = {
    0: ('excavator', 'æŒ–æ˜æœº'),
    1: ('bulldozer', 'æ¨åœŸæœº'),
    2: ('roller', 'å‹è·¯æœº'),
    3: ('loader', 'è£…è½½æœº'),
    4: ('dump-truck', 'è‡ªå¸è½¦'),
    5: ('concrete-mixer', 'æ··å‡åœŸæ…æ‹Œè½¦'),
    6: ('pump-truck', 'æ³µè½¦'),
    7: ('crane', 'èµ·é‡æœº'),
}

CIVILIAN_VEHICLES = {
    8: ('truck', 'å¡è½¦'),
    9: ('car', 'è½¿è½¦'),
}

ALL_CLASSES = {**CONSTRUCTION_VEHICLES, **CIVILIAN_VEHICLES}

# æ¯ä¸ªç±»åˆ«çš„é¢œè‰²ï¼ˆBGRæ ¼å¼ï¼‰
CLASS_COLORS = {
    0: (0, 255, 0),      # æŒ–æ˜æœº - ç»¿è‰²
    1: (0, 255, 127),    # æ¨åœŸæœº - æ˜¥ç»¿è‰²
    2: (0, 255, 255),    # å‹è·¯æœº - é»„è‰²
    3: (0, 200, 0),      # è£…è½½æœº - æ·±ç»¿è‰²
    4: (0, 180, 180),    # è‡ªå¸è½¦ - æ©„æ¦„ç»¿
    5: (0, 220, 100),    # æ··å‡åœŸæ…æ‹Œè½¦ - é»„ç»¿è‰²
    6: (0, 160, 200),    # æ³µè½¦ - é‡‘é»„è‰²
    7: (100, 255, 100),  # èµ·é‡æœº - æµ…ç»¿è‰²
    8: (255, 0, 0),      # å¡è½¦ - è“è‰²
    9: (255, 100, 200),  # è½¿è½¦ - ç²‰è“è‰²
}


class TensorRTInference:
    """TensorRTæ¨ç†å¼•æ“"""
    
    def __init__(self, engine_path, input_shape=(640, 640)):
        """
        Args:
            engine_path: TensorRTå¼•æ“æ–‡ä»¶è·¯å¾„
            input_shape: è¾“å…¥å›¾åƒå¤§å° (height, width)
        """
        self.engine_path = engine_path
        self.input_shape = input_shape
        
        # åŠ è½½å¼•æ“
        print(f"\nåŠ è½½TensorRTå¼•æ“: {engine_path}")
        self.logger = trt.Logger(trt.Logger.WARNING)
        
        with open(engine_path, 'rb') as f:
            engine_data = f.read()
        
        runtime = trt.Runtime(self.logger)
        self.engine = runtime.deserialize_cuda_engine(engine_data)
        self.context = self.engine.create_execution_context()
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯ï¼ˆå…¼å®¹TensorRT 10.xï¼‰
        # TensorRT 10.xä½¿ç”¨æ–°API
        if hasattr(self.engine, 'get_tensor_name'):
            # TensorRT 10.x
            self.input_name = self.engine.get_tensor_name(0)
            self.output_name = self.engine.get_tensor_name(1)
            self.input_shape_trt = self.engine.get_tensor_shape(self.input_name)
            self.output_shape = self.engine.get_tensor_shape(self.output_name)
        else:
            # TensorRT 8.x
            self.input_name = self.engine.get_binding_name(0)
            self.output_name = self.engine.get_binding_name(1)
            self.input_shape_trt = self.engine.get_binding_shape(0)
            self.output_shape = self.engine.get_binding_shape(1)
        
        print(f"  è¾“å…¥: {self.input_name} {list(self.input_shape_trt)}")
        print(f"  è¾“å‡º: {self.output_name} {list(self.output_shape)}")
        
        # åˆ†é…GPUå†…å­˜
        self.input_size = trt.volume(self.input_shape_trt) * np.dtype(np.float32).itemsize
        self.output_size = trt.volume(self.output_shape) * np.dtype(np.float32).itemsize
        
        self.d_input = cuda.mem_alloc(self.input_size)
        self.d_output = cuda.mem_alloc(self.output_size)
        
        self.bindings = [int(self.d_input), int(self.d_output)]
        self.stream = cuda.Stream()
        
        print("âœ“ TensorRTå¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def preprocess(self, image):
        """
        é¢„å¤„ç†å›¾åƒ
        Args:
            image: OpenCVå›¾åƒ (BGR)
        Returns:
            preprocessed: é¢„å¤„ç†åçš„å›¾åƒ (1, 3, 640, 640)
            ratio: ç¼©æ”¾æ¯”ä¾‹
            (dw, dh): padding
        """
        h, w = image.shape[:2]
        target_h, target_w = self.input_shape
        
        # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼ˆä¿æŒå®½é«˜æ¯”ï¼‰
        ratio = min(target_w / w, target_h / h)
        new_w = int(w * ratio)
        new_h = int(h * ratio)
        
        # ç¼©æ”¾
        resized = cv2.resize(image, (new_w, new_h))
        
        # å¡«å……åˆ°ç›®æ ‡å¤§å°
        dw = (target_w - new_w) // 2
        dh = (target_h - new_h) // 2
        
        padded = np.full((target_h, target_w, 3), 114, dtype=np.uint8)
        padded[dh:dh+new_h, dw:dw+new_w] = resized
        
        # BGR -> RGB, HWC -> CHW, normalize
        image_rgb = cv2.cvtColor(padded, cv2.COLOR_BGR2RGB)
        image_chw = np.transpose(image_rgb, (2, 0, 1))
        image_norm = image_chw.astype(np.float32) / 255.0
        image_batch = np.expand_dims(image_norm, axis=0)
        
        return np.ascontiguousarray(image_batch), ratio, (dw, dh)
    
    def infer(self, image_batch):
        """
        æ‰§è¡Œæ¨ç†
        Args:
            image_batch: é¢„å¤„ç†åçš„å›¾åƒ (1, 3, 640, 640)
        Returns:
            output: æ¨ç†ç»“æœ (1, 14, 8400)
        """
        # å¤åˆ¶è¾“å…¥åˆ°GPU
        cuda.memcpy_htod_async(self.d_input, image_batch, self.stream)
        
        # æ‰§è¡Œæ¨ç†ï¼ˆå…¼å®¹TensorRT 10.xï¼‰
        if hasattr(self.context, 'execute_async_v3'):
            # TensorRT 10.xä½¿ç”¨æ–°API
            self.context.set_tensor_address(self.input_name, int(self.d_input))
            self.context.set_tensor_address(self.output_name, int(self.d_output))
            self.context.execute_async_v3(stream_handle=self.stream.handle)
        else:
            # TensorRT 8.xä½¿ç”¨æ—§API
            self.context.execute_async_v2(
                bindings=self.bindings,
                stream_handle=self.stream.handle
            )
        
        # å¤åˆ¶è¾“å‡ºåˆ°CPU
        output = np.empty(self.output_shape, dtype=np.float32)
        cuda.memcpy_dtoh_async(output, self.d_output, self.stream)
        
        self.stream.synchronize()
        
        return output
    
    def postprocess(self, output, ratio, pad, conf_threshold=0.25, iou_threshold=0.45, debug=False):
        """
        åå¤„ç†YOLOv11è¾“å‡º
        Args:
            output: (1, 14, 8400) - [x, y, w, h, conf, class0...class9]
            ratio: ç¼©æ”¾æ¯”ä¾‹
            pad: (dw, dh) padding
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: NMS IoUé˜ˆå€¼
            debug: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
        Returns:
            detections: List of (x1, y1, x2, y2, conf, class_id)
        """
        output = output[0]  # (14, 8400)
        
        if debug:
            print(f"\n[è°ƒè¯•] åŸå§‹è¾“å‡ºshape: {output.shape}")
            print(f"[è°ƒè¯•] è¾“å‡ºèŒƒå›´: [{output.min():.3f}, {output.max():.3f}]")
        
        # è½¬ç½®ä¸º (8400, 14)
        predictions = output.transpose()  # (8400, 14)
        
        # YOLOv11è¾“å‡ºæ ¼å¼: [x, y, w, h, class0, class1, ..., class9]
        # æ³¨æ„ï¼šYOLOv11å¯èƒ½å·²ç»æ²¡æœ‰å•ç‹¬çš„objectnessï¼Œç›´æ¥æ˜¯class scores
        boxes_xywh = predictions[:, :4]  # (8400, 4) [x, y, w, h]
        class_scores = predictions[:, 4:]  # (8400, 10) ç›´æ¥çš„ç±»åˆ«åˆ†æ•°
        
        if debug:
            print(f"[è°ƒè¯•] boxesèŒƒå›´: [{boxes_xywh.min():.3f}, {boxes_xywh.max():.3f}]")
            print(f"[è°ƒè¯•] class_scoresèŒƒå›´: [{class_scores.min():.3f}, {class_scores.max():.3f}]")
            print(f"[è°ƒè¯•] class_scoreså‰5ä¸ªæœ€å¤§å€¼: {np.sort(class_scores.flatten())[-5:]}")
        
        # ç›´æ¥ä½¿ç”¨class scores
        class_ids = np.argmax(class_scores, axis=1)  # (8400,)
        confidences = np.max(class_scores, axis=1)  # (8400,)
        
        if debug:
            print(f"[è°ƒè¯•] æœ€å¤§ç½®ä¿¡åº¦: {confidences.max():.3f}")
            print(f"[è°ƒè¯•] >0.1çš„æ•°é‡: {(confidences > 0.1).sum()}")
            print(f"[è°ƒè¯•] >0.25çš„æ•°é‡: {(confidences > 0.25).sum()}")
            print(f"[è°ƒè¯•] >0.5çš„æ•°é‡: {(confidences > 0.5).sum()}")
        
        # è¿‡æ»¤ä½ç½®ä¿¡åº¦
        mask = confidences > conf_threshold
        boxes_xywh = boxes_xywh[mask]
        confidences = confidences[mask]
        class_ids = class_ids[mask]
        
        if debug:
            print(f"[è°ƒè¯•] è¿‡æ»¤åå‰©ä½™: {len(boxes_xywh)} ä¸ªæ£€æµ‹")
        
        if len(boxes_xywh) == 0:
            return []
        
        # xywh -> xyxy
        boxes_xyxy = np.zeros_like(boxes_xywh)
        boxes_xyxy[:, 0] = boxes_xywh[:, 0] - boxes_xywh[:, 2] / 2  # x1
        boxes_xyxy[:, 1] = boxes_xywh[:, 1] - boxes_xywh[:, 3] / 2  # y1
        boxes_xyxy[:, 2] = boxes_xywh[:, 0] + boxes_xywh[:, 2] / 2  # x2
        boxes_xyxy[:, 3] = boxes_xywh[:, 1] + boxes_xywh[:, 3] / 2  # y2
        
        # è¿˜åŸåˆ°åŸå›¾åæ ‡
        dw, dh = pad
        boxes_xyxy[:, [0, 2]] = (boxes_xyxy[:, [0, 2]] - dw) / ratio
        boxes_xyxy[:, [1, 3]] = (boxes_xyxy[:, [1, 3]] - dh) / ratio
        
        # NMS
        indices = self.nms(boxes_xyxy, confidences, iou_threshold)
        
        detections = []
        for i in indices:
            x1, y1, x2, y2 = boxes_xyxy[i]
            conf = confidences[i]
            cls = class_ids[i]
            detections.append((x1, y1, x2, y2, conf, cls))
        
        return detections
    
    @staticmethod
    def nms(boxes, scores, iou_threshold):
        """
        Non-Maximum Suppression
        Args:
            boxes: (N, 4) [x1, y1, x2, y2]
            scores: (N,)
            iou_threshold: IoUé˜ˆå€¼
        Returns:
            indices: ä¿ç•™çš„ç´¢å¼•
        """
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]
        
        areas = (x2 - x1) * (y2 - y1)
        order = scores.argsort()[::-1]
        
        keep = []
        while order.size > 0:
            i = order[0]
            keep.append(i)
            
            xx1 = np.maximum(x1[i], x1[order[1:]])
            yy1 = np.maximum(y1[i], y1[order[1:]])
            xx2 = np.minimum(x2[i], x2[order[1:]])
            yy2 = np.minimum(y2[i], y2[order[1:]])
            
            w = np.maximum(0.0, xx2 - xx1)
            h = np.maximum(0.0, yy2 - yy1)
            inter = w * h
            
            iou = inter / (areas[i] + areas[order[1:]] - inter)
            
            inds = np.where(iou <= iou_threshold)[0]
            order = order[inds + 1]
        
        return keep


class VehicleDetectionSystem:
    """è½¦è¾†æ£€æµ‹ç³»ç»Ÿï¼ˆæ··åˆæ–¹æ¡ˆï¼‰"""
    
    def __init__(self, engine_path, video_source, no_display=False, 
                 cassia_config=None, use_depth_camera=False):
        """
        Args:
            engine_path: TensorRTå¼•æ“è·¯å¾„
            video_source: è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–'camera'
            no_display: æ˜¯å¦ç¦ç”¨æ˜¾ç¤ºçª—å£
            cassia_config: Cassiaé…ç½® {'mode': 'local', 'router_ip': x}
            use_depth_camera: æ˜¯å¦ä½¿ç”¨æ·±åº¦ç›¸æœº
        """
        self.engine_path = engine_path
        self.video_source = video_source
        self.no_display = no_display
        self.use_depth_camera = use_depth_camera
        
        # åˆå§‹åŒ–TensorRT
        self.trt_engine = TensorRTInference(engine_path)
        
        # åˆå§‹åŒ–Orbbecæ·±åº¦ç›¸æœº
        self.depth_camera = None
        if use_depth_camera:
            try:
                from orbbec_depth import OrbbecDepthCamera
                self.depth_camera = OrbbecDepthCamera()
                if self.depth_camera.start():
                    print("âœ“ Orbbecæ·±åº¦ç›¸æœºå¯åŠ¨æˆåŠŸ")
                else:
                    print("âœ— Orbbecæ·±åº¦ç›¸æœºå¯åŠ¨å¤±è´¥ï¼Œä½¿ç”¨ç®€å•ä¼°è®¡")
                    self.depth_camera = None
            except Exception as e:
                print(f"âœ— Orbbecæ·±åº¦ç›¸æœºåˆå§‹åŒ–å¤±è´¥: {e}")
                print("  å°†ä½¿ç”¨ç®€å•è·ç¦»ä¼°è®¡")
                self.depth_camera = None
        
        # åˆå§‹åŒ–HyperLPR
        self.lpr = None
        if HYPERLPR_AVAILABLE:
            try:
                self.lpr = LicensePlateCN(detect_level=1, max_num=5)
                print("âœ“ HyperLPRåˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âœ— HyperLPRåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–Cassiaä¿¡æ ‡å®¢æˆ·ç«¯
        self.beacon_client = None
        if cassia_config:
            try:
                if cassia_config.get('mode') == 'local':
                    # æœ¬åœ°è·¯ç”±å™¨æ¨¡å¼
                    from cassia_local_client import CassiaLocalClient
                    self.beacon_client = CassiaLocalClient(
                        cassia_config['router_ip'],
                        cassia_config.get('username'),
                        cassia_config.get('password')
                    )
                    self.beacon_client.start()
                    print(f"âœ“ Cassiaæœ¬åœ°è·¯ç”±å™¨å¯åŠ¨æˆåŠŸ ({cassia_config['router_ip']})")
                else:
                    # ACæ¨¡å¼
                    from cassia_beacon_client import CassiaBeaconClient
                    self.beacon_client = CassiaBeaconClient(
                        cassia_config['ac_url'],
                        cassia_config['key'],
                        cassia_config['secret'],
                        cassia_config['router_mac']
                    )
                    self.beacon_client.start()
                    print("âœ“ Cassiaä¿¡æ ‡å®¢æˆ·ç«¯å¯åŠ¨æˆåŠŸï¼ˆACæ¨¡å¼ï¼‰")
            except Exception as e:
                print(f"âœ— Cassiaä¿¡æ ‡å®¢æˆ·ç«¯å¯åŠ¨å¤±è´¥: {e}")
                print("  å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆæ‰€æœ‰å·¥ç¨‹è½¦è¾†æ˜¾ç¤º'æœªå¤‡æ¡ˆ'ï¼‰")
        
        # ç»Ÿè®¡
        self.stats = {
            'construction_verified': [],  # å·²éªŒè¯çš„å·¥ç¨‹è½¦è¾†ï¼ˆä¿¡æ ‡åŒ¹é…ï¼‰
            'construction_unverified': [],  # æœªå¤‡æ¡ˆçš„å·¥ç¨‹è½¦è¾†
            'civilian_plates': [],  # è¯†åˆ«åˆ°çš„è½¦ç‰Œ
            'frame_count': 0,
            'fps': 0,
        }
        
        # è·Ÿè¸ªçŠ¶æ€
        self.tracked_vehicles = {}  # {track_id: {'bbox': [x1,y1,x2,y2], 'class_id': x, 'first_frame': x, 'last_frame': x, 'processed': bool}}
        self.next_track_id = 1
        self.iou_threshold = 0.3  # IoUé˜ˆå€¼ç”¨äºåŒ¹é…
        self.max_disappeared = 30  # æœ€å¤§æ¶ˆå¤±å¸§æ•°
        self.process_distance_threshold = 50  # è·ç¦»å˜åŒ–è¶…è¿‡50åƒç´ æ‰é‡æ–°å¤„ç†ï¼ˆé¿å…é‡å¤ï¼‰
    
    def process_video(self, output_path=None):
        """å¤„ç†è§†é¢‘"""
        
        # æ‰“å¼€è§†é¢‘
        if self.video_source == 'camera':
            cap = cv2.VideoCapture(0)
        else:
            cap = cv2.VideoCapture(self.video_source)
        
        if not cap.isOpened():
            print(f"âœ— æ— æ³•æ‰“å¼€è§†é¢‘: {self.video_source}")
            return
        
        fps_cap = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"\nè§†é¢‘ä¿¡æ¯:")
        print(f"  åˆ†è¾¨ç‡: {width}x{height}")
        print(f"  å¸§ç‡: {fps_cap:.2f} FPS")
        print(f"  æ€»å¸§æ•°: {total_frames}")
        print(f"\nå¼€å§‹å¤„ç†...")
        
        # è¾“å‡ºè§†é¢‘ï¼ˆå¯é€‰ï¼‰
        writer = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            writer = cv2.VideoWriter(output_path, fourcc, fps_cap, (width, height))
        
        # æ€§èƒ½ç»Ÿè®¡
        frame_times = []
        start_time = time.time()
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_start = time.time()
                
                # ç»Ÿè®¡
                frame_time = time.time() - frame_start
                frame_times.append(frame_time)
                self.stats['frame_count'] += 1
                
                # TensorRTæ¨ç†
                input_batch, ratio, pad = self.trt_engine.preprocess(frame)
                output = self.trt_engine.infer(input_batch)
                
                # ç¬¬ä¸€å¸§è¾“å‡ºè°ƒè¯•ä¿¡æ¯
                debug = (self.stats['frame_count'] == 1)
                detections = self.trt_engine.postprocess(output, ratio, pad, debug=debug)
                
                # å‰å‡ å¸§æ˜¾ç¤ºæ£€æµ‹æ•°é‡
                if self.stats['frame_count'] <= 10:
                    print(f"  å¸§{self.stats['frame_count']}: {len(detections)} ä¸ªæ£€æµ‹")
                
                # IoUè·Ÿè¸ª + ä¿¡æ ‡åŒ¹é… + è½¦ç‰Œè¯†åˆ«ï¼ˆè¿”å›å¸¦track_idçš„æ£€æµ‹ï¼‰
                tracked_detections = self.iou_tracking(detections, frame)
                
                # è®¡ç®—FPS
                if len(frame_times) > 30:
                    frame_times = frame_times[-30:]
                avg_fps = 1.0 / np.mean(frame_times)
                self.stats['fps'] = avg_fps
                
                # ç»˜åˆ¶ç»“æœå’ŒFPS
                self.draw_results(frame, tracked_detections, avg_fps)
                
                # å†™å…¥è¾“å‡º
                if writer:
                    writer.write(frame)
                
                # æ˜¾ç¤ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if not self.no_display:
                    cv2.imshow('TensorRT Vehicle Detection', frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                
                # è¿›åº¦
                if self.stats['frame_count'] % 100 == 0:
                    elapsed = time.time() - start_time
                    print(f"  å·²å¤„ç† {self.stats['frame_count']}/{total_frames} å¸§, "
                          f"å¹³å‡ {avg_fps:.1f} FPS, ç”¨æ—¶ {elapsed:.1f}s")
        
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­")
        
        finally:
            cap.release()
            if writer:
                writer.release()
            cv2.destroyAllWindows()
            
            # åœæ­¢ä¿¡æ ‡å®¢æˆ·ç«¯
            if self.beacon_client:
                self.beacon_client.stop()
            
            # åœæ­¢æ·±åº¦ç›¸æœº
            if self.depth_camera:
                self.depth_camera.stop()
            
            # æ‰“å°ç»Ÿè®¡
            self.print_statistics()
    
    @staticmethod
    def compute_iou(box1, box2):
        """è®¡ç®—ä¸¤ä¸ªbboxçš„IoU"""
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        # è®¡ç®—äº¤é›†
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i < x1_i or y2_i < y1_i:
            return 0.0
        
        inter_area = (x2_i - x1_i) * (y2_i - y1_i)
        
        # è®¡ç®—å¹¶é›†
        box1_area = (x2_1 - x1_1) * (y2_1 - y1_1)
        box2_area = (x2_2 - x1_2) * (y2_2 - y1_2)
        union_area = box1_area + box2_area - inter_area
        
        return inter_area / union_area if union_area > 0 else 0.0
    
    def calculate_distance(self, bbox, frame_shape):
        """
        è®¡ç®—è½¦è¾†åˆ°ç›¸æœºçš„è·ç¦»
        Args:
            bbox: [x1, y1, x2, y2]
            frame_shape: å¸§çš„shape
        Returns:
            distance: è·ç¦»ï¼ˆç±³ï¼‰
            bottom_center: bboxåº•è¾¹ä¸­ç‚¹åæ ‡ (x, y)
        """
        x1, y1, x2, y2 = bbox
        # bboxåº•è¾¹ä¸­ç‚¹
        bottom_center_x = int((x1 + x2) / 2)
        bottom_center_y = int(y2)
        
        # å¦‚æœæœ‰æ·±åº¦ç›¸æœºï¼Œä½¿ç”¨çœŸå®æ·±åº¦
        if self.depth_camera:
            depth = self.depth_camera.get_average_depth_at_bbox_bottom(bbox, radius=5)
            if depth is not None:
                return depth, (bottom_center_x, bottom_center_y)
        
        # å¦åˆ™ä½¿ç”¨ç®€å•çš„bboxé«˜åº¦åæ¯”ä¾‹ä¼°è®¡
        bbox_height = y2 - y1
        estimated_distance = 1000 / max(bbox_height, 1)  # ç®€å•åæ¯”ä¾‹
        
        return estimated_distance, (bottom_center_x, bottom_center_y)
    
    def match_beacon(self, distance, class_id):
        """
        åŒ¹é…è“ç‰™ä¿¡æ ‡
        Args:
            distance: ä¼°è®¡è·ç¦»ï¼ˆç±³ï¼‰
            class_id: è½¦è¾†ç±»åˆ«
        Returns:
            beacon_id: ä¿¡æ ‡MACåœ°å€ï¼ˆå¦‚æœåŒ¹é…åˆ°ï¼‰ï¼Œå¦åˆ™None
        """
        if self.beacon_client is None:
            # æœªå¯ç”¨ä¿¡æ ‡å®¢æˆ·ç«¯
            return None
        
        # æŸ¥æ‰¾æœ€æ¥è¿‘çš„ä¿¡æ ‡
        beacon = self.beacon_client.find_nearest_beacon(distance, tolerance=2.5)
        
        if beacon:
            return beacon['mac']
        
        return None
    
    def recognize_plate(self, frame, bbox):
        """
        è¯†åˆ«è½¦ç‰Œï¼ˆHyperLPRï¼‰
        Args:
            frame: åŸå§‹å¸§
            bbox: [x1, y1, x2, y2]
        Returns:
            plate: è½¦ç‰Œå·ï¼ŒNone if è¯†åˆ«å¤±è´¥
        """
        if self.lpr is None:
            return None
        
        try:
            x1, y1, x2, y2 = [int(v) for v in bbox]
            # æ‰©å¤§ROIï¼ˆè½¦ç‰Œé€šå¸¸åœ¨è½¦è¾†ä¸‹éƒ¨ï¼‰
            h, w = frame.shape[:2]
            y1 = max(0, y1)
            y2 = min(h, y2)
            x1 = max(0, x1)
            x2 = min(w, x2)
            
            roi = frame[y1:y2, x1:x2]
            
            if roi.size == 0:
                return None
            
            # HyperLPRè¯†åˆ«
            results = self.lpr.simple_recognize(roi)
            
            if results and len(results) > 0:
                plate, confidence = results[0]
                if confidence > 0.7:  # ç½®ä¿¡åº¦é˜ˆå€¼
                    return plate
        except Exception as e:
            pass
        
        return None
    
    def iou_tracking(self, detections, frame):
        """
        åŸºäºIoUçš„è·Ÿè¸ª + å·¥ç¨‹è½¦è¾†ä¿¡æ ‡åŒ¹é… + ç¤¾ä¼šè½¦è¾†è½¦ç‰Œè¯†åˆ«
        """
        current_frame = self.stats['frame_count']
        
        # æ¸…ç†æ¶ˆå¤±å¤ªä¹…çš„è·Ÿè¸ª
        to_remove = []
        for track_id, track_info in self.tracked_vehicles.items():
            if current_frame - track_info['last_frame'] > self.max_disappeared:
                to_remove.append(track_id)
        
        for track_id in to_remove:
            del self.tracked_vehicles[track_id]
        
        # åŒ¹é…å½“å‰æ£€æµ‹ä¸å·²æœ‰è·Ÿè¸ª
        tracked_detections = []
        matched_tracks = set()
        new_detections = []
        
        for det in detections:
            x1, y1, x2, y2, conf, cls = det
            cls = int(cls)
            det_bbox = [x1, y1, x2, y2]
            
            # å¯»æ‰¾æœ€ä½³åŒ¹é…
            best_iou = 0
            best_track_id = None
            
            for track_id, track_info in self.tracked_vehicles.items():
                if track_info['class_id'] != cls:
                    continue
                if track_id in matched_tracks:
                    continue
                
                iou = self.compute_iou(det_bbox, track_info['bbox'])
                
                if iou > self.iou_threshold and iou > best_iou:
                    best_iou = iou
                    best_track_id = track_id
            
            if best_track_id is not None:
                # åŒ¹é…åˆ°å·²æœ‰è·Ÿè¸ªï¼Œæ›´æ–°
                self.tracked_vehicles[best_track_id]['bbox'] = det_bbox
                self.tracked_vehicles[best_track_id]['last_frame'] = current_frame
                matched_tracks.add(best_track_id)
                tracked_detections.append((x1, y1, x2, y2, conf, cls, best_track_id))
            else:
                # æ–°æ£€æµ‹
                new_detections.append((det_bbox, cls, conf))
        
        # å¤„ç†æ–°æ£€æµ‹
        for det_bbox, cls, conf in new_detections:
            track_id = self.next_track_id
            self.next_track_id += 1
            
            self.tracked_vehicles[track_id] = {
                'bbox': det_bbox,
                'class_id': cls,
                'first_frame': current_frame,
                'last_frame': current_frame,
                'processed': False,
                'beacon_id': None,
                'plate': None,
            }
            
            # å·¥ç¨‹è½¦è¾†ï¼šè·ç¦»è®¡ç®— + ä¿¡æ ‡åŒ¹é…
            if cls in CONSTRUCTION_VEHICLES:
                distance, bottom_center = self.calculate_distance(det_bbox, frame.shape)
                beacon_id = self.match_beacon(distance, cls)
                
                vtype, cn_name = CONSTRUCTION_VEHICLES[cls]
                
                if beacon_id:
                    # åŒ¹é…åˆ°ä¿¡æ ‡
                    self.tracked_vehicles[track_id]['beacon_id'] = beacon_id
                    self.stats['construction_verified'].append({
                        'track_id': track_id,
                        'type': vtype,
                        'beacon_id': beacon_id,
                        'frame': current_frame
                    })
                    print(f"  âœ“ å·²å¤‡æ¡ˆè½¦è¾† ID{track_id}: {cn_name}, ä¿¡æ ‡={beacon_id}")
                else:
                    # æœªåŒ¹é…åˆ°ä¿¡æ ‡ - æœªå¤‡æ¡ˆè½¦è¾†
                    self.stats['construction_unverified'].append({
                        'track_id': track_id,
                        'type': vtype,
                        'frame': current_frame
                    })
                    print(f"  âš  æœªå¤‡æ¡ˆè½¦è¾†å…¥åœº! ID{track_id}: {cn_name}, å¸§{current_frame}")
                
                self.tracked_vehicles[track_id]['processed'] = True
            
            # ç¤¾ä¼šè½¦è¾†ï¼šè½¦ç‰Œè¯†åˆ«
            elif cls in CIVILIAN_VEHICLES:
                plate = self.recognize_plate(frame, det_bbox)
                
                vtype, cn_name = CIVILIAN_VEHICLES[cls]
                
                if plate:
                    self.tracked_vehicles[track_id]['plate'] = plate
                    self.stats['civilian_plates'].append({
                        'track_id': track_id,
                        'plate': plate,
                        'type': vtype,
                        'frame': current_frame
                    })
                    print(f"  ğŸš— ç¤¾ä¼šè½¦è¾† ID{track_id}: {cn_name}, è½¦ç‰Œ={plate}")
                else:
                    print(f"  ğŸš— ç¤¾ä¼šè½¦è¾† ID{track_id}: {cn_name}, è½¦ç‰Œè¯†åˆ«å¤±è´¥")
                
                self.tracked_vehicles[track_id]['processed'] = True
            
            # æ·»åŠ åˆ°ç»“æœ
            x1, y1, x2, y2 = det_bbox
            tracked_detections.append((x1, y1, x2, y2, conf, cls, track_id))
        
        return tracked_detections
    
    def draw_results(self, frame, detections, fps=0):
        """ç»˜åˆ¶æ£€æµ‹ç»“æœï¼ˆçº¯OpenCVï¼Œå¿«é€Ÿå¯é ï¼‰"""
        # ç»˜åˆ¶æ‰€æœ‰æ£€æµ‹æ¡†å’Œæ ‡ç­¾
        for det in detections:
            # è§£åŒ…ï¼ˆå¸¦track_idï¼‰
            if len(det) == 7:
                x1, y1, x2, y2, conf, cls, track_id = det
            else:
                x1, y1, x2, y2, conf, cls = det
                track_id = None
            
            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
            cls = int(cls)
            
            # è·å–é¢œè‰²å’Œæ ‡ç­¾ï¼ˆä½¿ç”¨è‹±æ–‡ï¼‰
            color = CLASS_COLORS.get(cls, (128, 128, 128))
            
            if cls in CONSTRUCTION_VEHICLES:
                label_en, label_cn = CONSTRUCTION_VEHICLES[cls]
            elif cls in CIVILIAN_VEHICLES:
                label_en, label_cn = CIVILIAN_VEHICLES[cls]
            else:
                label_en = f"class{cls}"
            
            # ç»˜åˆ¶æ¡†
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 3)
            
            # ç»˜åˆ¶æ ‡ç­¾ï¼ˆID + ç±»å‹ + ç½®ä¿¡åº¦ï¼‰
            if track_id is not None:
                label_text = f"ID{track_id} {label_en} {conf:.2f}"
            else:
                label_text = f"{label_en} {conf:.2f}"
            
            # æ ‡ç­¾èƒŒæ™¯
            (w, h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(frame, (x1, y1 - 25), (x1 + w + 10, y1), color, -1)
            
            # æ ‡ç­¾æ–‡å­—
            cv2.putText(frame, label_text, (x1 + 5, y1 - 5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯ï¼ˆå³ä¸Šè§’ï¼‰
        stats_text = f"Tracked: {len(self.tracked_vehicles)}"
        cv2.rectangle(frame, (frame.shape[1] - 200, 5), (frame.shape[1] - 5, 40), (0, 0, 0), -1)
        cv2.putText(frame, stats_text, (frame.shape[1] - 195, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
        
        # ç»˜åˆ¶FPSï¼ˆå·¦ä¸Šè§’ï¼‰
        if fps > 0:
            fps_text = f"FPS: {fps:.1f}"
            cv2.rectangle(frame, (5, 5), (150, 40), (0, 0, 0), -1)
            cv2.putText(frame, fps_text, (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print("\n" + "="*70)
        print("TensorRTè½¦è¾†æ£€æµ‹ç»Ÿè®¡")
        print("="*70)
        
        print(f"\næ€»å¸§æ•°: {self.stats['frame_count']}")
        print(f"å¹³å‡FPS: {self.stats['fps']:.1f}")
        
        print("\nã€å·¥ç¨‹è½¦è¾† - å·²å¤‡æ¡ˆã€‘")
        if self.stats['construction_verified']:
            print(f"  æ€»æ•°: {len(self.stats['construction_verified'])} è¾†\n")
            for item in self.stats['construction_verified']:
                vtype = item['type']
                beacon_id = item['beacon_id']
                track_id = item['track_id']
                print(f"  ID{track_id}: {vtype:15s} ä¿¡æ ‡={beacon_id}")
        else:
            print("  æ— ")
        
        print("\nã€å·¥ç¨‹è½¦è¾† - æœªå¤‡æ¡ˆï¼ˆè­¦å‘Šï¼‰ã€‘")
        if self.stats['construction_unverified']:
            print(f"  æ€»æ•°: {len(self.stats['construction_unverified'])} è¾†\n")
            for item in self.stats['construction_unverified']:
                vtype = item['type']
                track_id = item['track_id']
                frame = item['frame']
                print(f"  âš  ID{track_id}: {vtype:15s} å¸§{frame}")
        else:
            print("  æ— ")
        
        print("\nã€ç¤¾ä¼šè½¦è¾† - è½¦ç‰Œè¯†åˆ«ã€‘")
        if self.stats['civilian_plates']:
            print(f"  æ€»æ•°: {len(self.stats['civilian_plates'])} è¾†\n")
            for item in self.stats['civilian_plates']:
                track_id = item['track_id']
                plate = item['plate']
                vtype = item['type']
                print(f"  ID{track_id}: {vtype:10s} è½¦ç‰Œ={plate}")
        else:
            print("  æ— ")
        
        print("\n" + "="*70)


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='TensorRTè½¦è¾†æ£€æµ‹ï¼ˆæ··åˆæ–¹æ¡ˆï¼‰')
    parser.add_argument('video', help='è§†é¢‘æ–‡ä»¶è·¯å¾„æˆ–camera')
    parser.add_argument('--engine', default='models/yolov11.engine',
                       help='TensorRTå¼•æ“è·¯å¾„')
    parser.add_argument('--output', help='è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--no-display', action='store_true',
                       help='ä¸æ˜¾ç¤ºçª—å£ï¼ˆSSHæ¨¡å¼ï¼‰')
    
    # Cassiaä¿¡æ ‡é…ç½®
    parser.add_argument('--cassia-local', help='Cassiaæœ¬åœ°è·¯ç”±å™¨IPï¼Œå¦‚ 192.168.40.1')
    parser.add_argument('--cassia-user', help='Cassiaè·¯ç”±å™¨ç”¨æˆ·åï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--cassia-pass', help='Cassiaè·¯ç”±å™¨å¯†ç ï¼ˆå¯é€‰ï¼‰')
    
    # ACæ¨¡å¼ï¼ˆé«˜çº§ï¼‰
    parser.add_argument('--cassia-ac', help='Cassia ACåœ°å€ï¼Œå¦‚ http://192.168.1.100')
    parser.add_argument('--cassia-key', help='Cassiaå¼€å‘è€…å¯†é’¥')
    parser.add_argument('--cassia-secret', help='Cassiaå¼€å‘è€…å¯†ç ')
    parser.add_argument('--cassia-router', help='Cassiaè·¯ç”±å™¨MACåœ°å€')
    
    # æ·±åº¦ç›¸æœº
    parser.add_argument('--use-depth', action='store_true',
                       help='ä½¿ç”¨Orbbecæ·±åº¦ç›¸æœºè®¡ç®—è·ç¦»')
    
    args = parser.parse_args()
    
    print("="*70)
    print("å·¥ç¨‹æœºæ¢°å®æ—¶è¯†åˆ«ç³»ç»Ÿ")
    print("="*70)
    print("GPU: TensorRTæ¨ç†")
    print("CPU: YOLOåå¤„ç†ã€è·Ÿè¸ª")
    
    # Cassiaé…ç½®
    cassia_config = None
    if args.cassia_local:
        # æœ¬åœ°è·¯ç”±å™¨æ¨¡å¼
        cassia_config = {
            'mode': 'local',
            'router_ip': args.cassia_local,
            'username': args.cassia_user,
            'password': args.cassia_pass
        }
        print(f"ä¿¡æ ‡: Cassiaæœ¬åœ°è·¯ç”±å™¨ ({args.cassia_local})")
    elif args.cassia_ac and args.cassia_key and args.cassia_secret and args.cassia_router:
        # ACæ¨¡å¼
        cassia_config = {
            'mode': 'ac',
            'ac_url': args.cassia_ac,
            'key': args.cassia_key,
            'secret': args.cassia_secret,
            'router_mac': args.cassia_router
        }
        print("ä¿¡æ ‡: Cassiaè“ç‰™ä¿¡æ ‡ï¼ˆACæ¨¡å¼ï¼‰")
    else:
        print("ä¿¡æ ‡: æœªé…ç½®ï¼ˆæ‰€æœ‰å·¥ç¨‹è½¦è¾†å°†æ˜¾ç¤º'æœªå¤‡æ¡ˆ'ï¼‰")
    
    if args.use_depth:
        print("æ·±åº¦: Orbbecæ·±åº¦ç›¸æœºï¼ˆå·²å¯ç”¨ï¼‰")
    else:
        print("æ·±åº¦: ç®€å•ä¼°è®¡ï¼ˆåŸºäºbboxé«˜åº¦ï¼‰")
    
    print("è½¦ç‰Œ: HyperLPR" if HYPERLPR_AVAILABLE else "è½¦ç‰Œ: æœªå®‰è£…")
    print("="*70)
    
    if args.no_display:
        print("æ¨¡å¼: æ— æ˜¾ç¤ºï¼ˆSSHæ¨¡å¼ï¼‰")
    
    system = VehicleDetectionSystem(
        args.engine, 
        args.video, 
        args.no_display,
        cassia_config=cassia_config,
        use_depth_camera=args.use_depth
    )
    system.process_video(args.output)


if __name__ == '__main__':
    main()

